{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='wald-friedman'></a>\n",
    "<a href=\"#\"><img src=\"/_static/img/jupyter-notebook-download-blue.svg\" id=\"notebook_download_badge\"></a>\n",
    "\n",
    "<script>\n",
    "var path = window.location.pathname;\n",
    "var pageName = path.split(\"/\").pop().split(\".\")[0];\n",
    "var downloadLink = [\"/\", \"_downloads/ipynb/py/\", pageName, \".ipynb\"].join(\"\");\n",
    "document.getElementById('notebook_download_badge').parentElement.setAttribute('href', downloadLink);\n",
    "</script>\n",
    "\n",
    "<a href=\"/status.html\"><img src=\"https://img.shields.io/badge/Execution%20test-not%20available-lightgrey.svg\" id=\"executability_status_badge\"></a>\n",
    "\n",
    "<div class=\"how-to\">\n",
    "        <a href=\"#\" class=\"toggle\"><span class=\"icon icon-angle-double-down\"></span>How to read this lecture...</a>\n",
    "        <div class=\"how-to-content\">\n",
    "                <p>Code should execute sequentially if run in a Jupyter notebook</p>\n",
    "                <ul>\n",
    "                        <li>See the <a href=\"/py/getting_started.html\">set up page</a> to install Jupyter, Python and all necessary libraries</li>\n",
    "                        <li>Please direct feedback to <a href=\"mailto:contact@quantecon.org\">contact@quantecon.org</a> or the <a href=\"http://discourse.quantecon.org/\">discourse forum</a></li>\n",
    "                </ul>\n",
    "        </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Problem that Stumped Milton Friedman\n",
    "\n",
    "(and that Abraham Wald solved by inventing sequential analysis)\n",
    "\n",
    "\n",
    "<a id='index-1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [A Problem that Stumped Milton Friedman](#A-Problem-that-Stumped-Milton-Friedman)  \n",
    "  - [Overview](#Overview)  \n",
    "  - [Origin of the problem](#Origin-of-the-problem)  \n",
    "  - [A dynamic programming approach](#A-dynamic-programming-approach)  \n",
    "  - [Implementation](#Implementation)  \n",
    "  - [Analysis](#Analysis)  \n",
    "  - [Comparison with Neyman-Pearson formulation](#Comparison-with-Neyman-Pearson-formulation)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-authors: [Chase Coleman](https://github.com/cc7768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This lecture describes a statistical decision problem encountered  by Milton Friedman and W. Allen Wallis during World War II when they were analysts at the U.S. Government’s  Statistical Research Group at Columbia University\n",
    "\n",
    "This problem led Abraham Wald [[Wal47]](zreferences.ipynb#wald47) to formulate **sequential analysis**, an approach to statistical decision problems intimately related to dynamic programming\n",
    "\n",
    "In this lecture, we apply dynamic programming algorithms to Friedman and Wallis and Wald’s problem\n",
    "\n",
    "Key ideas in play will be:\n",
    "\n",
    "- Bayes’ Law  \n",
    "- Dynamic programming  \n",
    "- Type I and type II statistical errors  \n",
    "  - a type I error occurs when you reject a null hypothesis that is true  \n",
    "  - a type II error is when you accept a null hypothesis that is false  \n",
    "- Abraham Wald’s **sequential probability ratio test**  \n",
    "- The **power** of a statistical test  \n",
    "- The **critical region** of a statistical test  \n",
    "- A **uniformly most powerful test**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin of the problem\n",
    "\n",
    "On pages 137-139 of his 1998 book *Two Lucky People* with Rose Friedman [[FF98]](zreferences.ipynb#friedman98),\n",
    "Milton Friedman described a problem presented to him and Allen Wallis\n",
    "during World War II, when they worked at the US Government’s\n",
    "Statistical Research Group at Columbia University\n",
    "\n",
    "Let’s listen to Milton Friedman tell us what happened\n",
    "\n",
    "“In order to understand the story, it is necessary to have an idea of a\n",
    "simple statistical problem, and of the standard procedure for dealing\n",
    "with it. The actual problem out of which sequential analysis grew will\n",
    "serve. The Navy has two alternative designs (say A and B) for a\n",
    "projectile. It wants to determine which is superior. To do so it\n",
    "undertakes a series of paired firings. On each round it assigns the\n",
    "value 1 or 0 to A accordingly as its performance is superior or inferio\n",
    "to that of B and conversely 0 or 1 to B. The Navy asks the statistician\n",
    "how to conduct the test and how to analyze the results.\n",
    "\n",
    "“The standard statistical answer was to specify a number of firings (say\n",
    "1,000) and a pair of percentages (e.g., 53% and 47%) and tell the client\n",
    "that if A receives a 1 in more than 53% of the firings, it can be\n",
    "regarded as superior; if it receives a 1 in fewer than 47%, B can be\n",
    "regarded as superior; if the percentage is between 47% and 53%, neither\n",
    "can be so regarded.\n",
    "\n",
    "“When Allen Wallis was discussing such a problem with (Navy) Captain\n",
    "Garret L. Schyler, the captain objected that such a test, to quote from\n",
    "Allen’s account, may prove wasteful. If a wise and seasoned ordnance\n",
    "officer like Schyler were on the premises, he would see after the first\n",
    "few thousand or even few hundred [rounds] that the experiment need not\n",
    "be completed either because the new method is obviously inferior or\n",
    "because it is obviously superior beyond what was hoped for\n",
    "$ \\ldots $ “\n",
    "\n",
    "Friedman and Wallis struggled with the problem but, after realizing that\n",
    "they were not able to solve it,  described the problem to  Abraham Wald\n",
    "\n",
    "That started Wald on the path that led him  to *Sequential Analysis* [[Wal47]](zreferences.ipynb#wald47)\n",
    "\n",
    "We’ll formulate the problem using dynamic programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A dynamic programming approach\n",
    "\n",
    "The following presentation of the problem closely follows Dmitri\n",
    "Berskekas’s treatment in **Dynamic Programming and Stochastic Control** [[Ber75]](zreferences.ipynb#bertekas75)\n",
    "\n",
    "A decision maker observes iid draws of a random variable $ z $\n",
    "\n",
    "He (or she) wants to know which of two probability distributions $ f_0 $ or $ f_1 $ governs $ z $\n",
    "\n",
    "After a number of draws, also to be determined, he makes a decision as to which of the distributions is generating the draws he observers\n",
    "\n",
    "To help formalize the problem, let $ x \\in \\{x_0, x_1\\} $ be a hidden state that indexes the two distributions:\n",
    "\n",
    "$$\n",
    "\\mathbb P\\{z = v \\mid x \\}\n",
    "= \\begin{cases}\n",
    "    f_0(v) & \\mbox{if } x = x_0, \\\\\n",
    "    f_1(v) & \\mbox{if } x = x_1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Before observing any outcomes, the decision maker believes that the probability that $ x = x_0 $ is\n",
    "\n",
    "$$\n",
    "p_{-1} =\n",
    "\\mathbb P \\{ x=x_0 \\mid \\textrm{ no observations} \\} \\in (0, 1)\n",
    "$$\n",
    "\n",
    "After observing $ k+1 $ observations $ z_k, z_{k-1}, \\ldots, z_0 $, he updates this value to\n",
    "\n",
    "$$\n",
    "p_k = \\mathbb P \\{ x = x_0 \\mid z_k, z_{k-1}, \\ldots, z_0 \\},\n",
    "$$\n",
    "\n",
    "which is calculated recursively by applying Bayes’ law:\n",
    "\n",
    "$$\n",
    "p_{k+1} = \\frac{ p_k f_0(z_{k+1})}{ p_k f_0(z_{k+1}) + (1-p_k) f_1 (z_{k+1}) },\n",
    "\\quad k = -1, 0, 1, \\ldots\n",
    "$$\n",
    "\n",
    "After observing $ z_k, z_{k-1}, \\ldots, z_0 $, the decision maker believes that $ z_{k+1} $ has probability distribution\n",
    "\n",
    "$$\n",
    "f(v) = p_k f_0(v) + (1-p_k) f_1 (v)\n",
    "$$\n",
    "\n",
    "This is a mixture of distributions $ f_0 $ and $ f_1 $, with the weight on $ f_0 $ being the posterior probability that $ x = x_0 $ 1\n",
    "\n",
    "To help illustrate this kind of distribution, let’s inspect some mixtures of beta distributions\n",
    "\n",
    "The density of a beta probability distribution with parameters $ a $ and $ b $ is\n",
    "\n",
    "$$\n",
    "f(z; a, b) = \\frac{\\Gamma(a+b) z^{a-1} (1-z)^{b-1}}{\\Gamma(a) \\Gamma(b)}\n",
    "\\quad \\text{where} \\quad\n",
    "\\Gamma(t) := \\int_{0}^{\\infty} x^{t-1} e^{-x} dx\n",
    "$$\n",
    "\n",
    "We’ll discretize this distribution to make it more straightforward to work with\n",
    "\n",
    "The next figure shows two discretized beta distributions in the top panel\n",
    "\n",
    "The bottom panel presents mixtures of these distributions, with various mixing probabilities $ p_k $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "def make_distribution_plots(f0, f1):\n",
    "    \"\"\"\n",
    "    This generates the figure that shows the initial versions\n",
    "    of the distributions and plots their combinations.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, figsize=(10, 8))\n",
    "\n",
    "    axes[0].set_title(\"Original Distributions\")\n",
    "    axes[0].plot(f0, lw=2, label=\"$f_0$\")\n",
    "    axes[0].plot(f1, lw=2, label=\"$f_1$\")\n",
    "\n",
    "    axes[1].set_title(\"Mixtures\")\n",
    "    for p in 0.25, 0.5, 0.75:\n",
    "        y = p * f0 + (1 - p) * f1\n",
    "        axes[1].plot(y, lw=2, label=f\"$p_k$ = {p}\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.legend(fontsize=14)\n",
    "        ax.set_xlabel(\"$k$ values\", fontsize=14)\n",
    "        ax.set_ylabel(\"probability of $z_k$\", fontsize=14)\n",
    "        ax.set_ylim(0, 0.07)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "p_m1 = np.linspace(0, 1, 50)\n",
    "f0 = np.clip(st.beta.pdf(p_m1, a=1, b=1), 1e-8, np.inf)\n",
    "f0 = f0 / np.sum(f0)\n",
    "f1 = np.clip(st.beta.pdf(p_m1, a=9, b=9), 1e-8, np.inf)\n",
    "f1 = f1 / np.sum(f1)\n",
    "\n",
    "make_distribution_plots(f0, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and costs\n",
    "\n",
    "After observing $ z_k, z_{k-1}, \\ldots, z_0 $, the decision maker\n",
    "chooses among three distinct actions:\n",
    "\n",
    "- He decides that $ x = x_0 $ and draws no more $ z $‘s  \n",
    "- He decides that $ x = x_1 $ and draws no more $ z $‘s  \n",
    "- He postpones deciding now and instead chooses to draw a\n",
    "  $ z_{k+1} $  \n",
    "\n",
    "\n",
    "Associated with these three actions, the decision maker can suffer three\n",
    "kinds of losses:\n",
    "\n",
    "- A loss $ L_0 $ if he decides $ x = x_0 $ when actually\n",
    "  $ x=x_1 $  \n",
    "- A loss $ L_1 $ if he decides $ x = x_1 $ when actually\n",
    "  $ x=x_0 $  \n",
    "- A cost $ c $ if he postpones deciding and chooses instead to draw\n",
    "  another $ z $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digression on type I and type II errors\n",
    "\n",
    "If we regard  $ x=x_0 $ as a null hypothesis and $ x=x_1 $ as an alternative hypothesis,\n",
    "then $ L_1 $ and $ L_0 $ are losses associated with two types of statistical errors.\n",
    "\n",
    "- a type I error is an incorrect rejection of a true null hypothesis (a “false positive”)  \n",
    "- a type II error is a failure to reject a false null hypothesis (a “false negative”)  \n",
    "\n",
    "\n",
    "So when we treat $ x=x_0 $ as the null hypothesis\n",
    "\n",
    "- We can think of $ L_1 $ as the loss associated with a type I\n",
    "  error  \n",
    "- We can think of $ L_0 $ as the loss associated with a type II\n",
    "  error  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition\n",
    "\n",
    "Let’s try to guess what an optimal decision rule might look like before we go further\n",
    "\n",
    "Suppose at some given point in time that $ p $ is close to 1\n",
    "\n",
    "Then our prior beliefs and the evidence so far point strongly to $ x = x_0 $\n",
    "\n",
    "If, on the other hand, $ p $ is close to 0, then $ x = x_1 $ is strongly favored\n",
    "\n",
    "Finally, if $ p $ is in the middle of the interval $ [0, 1] $, then we have little information in either direction\n",
    "\n",
    "This reasoning suggests a decision rule such as the one shown in the figure\n",
    "\n",
    "<img src=\"_static/figures/wald_dec_rule.png\" style=\"width:40%;height:40%\">\n",
    "\n",
    "  \n",
    "As we’ll see, this is indeed the correct form of the decision rule\n",
    "\n",
    "The key problem is to determine the threshold values $ \\alpha, \\beta $,\n",
    "which will depend on the parameters listed above\n",
    "\n",
    "You might like to pause at this point and try to predict the impact of a\n",
    "parameter such as $ c $ or $ L_0 $ on $ \\alpha $ or $ \\beta $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Bellman equation\n",
    "\n",
    "Let $ J(p) $ be the total loss for a decision maker with current belief $ p $ who chooses optimally\n",
    "\n",
    "With some thought, you will agree that $ J $ should satisfy the Bellman equation\n",
    "\n",
    "\n",
    "<a id='equation-new1'></a>\n",
    "<table width=100%><tr style='background-color: #FFFFFF !important;'>\n",
    "<td width=10%></td>\n",
    "<td width=80%>\n",
    "$$\n",
    "J(p) =\n",
    "    \\min\n",
    "    \\left\\{\n",
    "        (1-p) L_0, \\; p L_1, \\;\n",
    "        c + \\mathbb E [ J (p') ]\n",
    "    \\right\\}\n",
    "$$\n",
    "</td><td width=10% style='text-align:center !important;'>\n",
    "(1)\n",
    "</td></tr></table>\n",
    "\n",
    "where $ p' $ is the random variable defined by\n",
    "\n",
    "$$\n",
    "p' = \\frac{ p f_0(z)}{ p f_0(z) + (1-p) f_1 (z) }\n",
    "$$\n",
    "\n",
    "when $ p $ is fixed and $ z $ is drawn from the current best guess, which is the distribution $ f $ defined by\n",
    "\n",
    "$$\n",
    "f(v) = p f_0(v) + (1-p) f_1 (v)\n",
    "$$\n",
    "\n",
    "In the Bellman equation, minimization is over three actions:\n",
    "\n",
    "1. accept $ x_0 $  \n",
    "1. accept $ x_1 $  \n",
    "1. postpone deciding and draw again  \n",
    "\n",
    "\n",
    "Let\n",
    "\n",
    "$$\n",
    "A(p)\n",
    ":= \\mathbb E [ J (p') ]\n",
    "$$\n",
    "\n",
    "Then we can represent the  Bellman equation as\n",
    "\n",
    "$$\n",
    "J(p) =\n",
    "\\min \\left\\{ (1-p) L_0, \\; p L_1, \\; c + A(p) \\right\\}\n",
    "$$\n",
    "\n",
    "where $ p \\in [0,1] $\n",
    "\n",
    "Here\n",
    "\n",
    "- $ (1-p) L_0 $ is the expected loss associated with accepting\n",
    "  $ x_0 $ (i.e., the cost of making a type II error)  \n",
    "- $ p L_1 $ is the expected loss associated with accepting\n",
    "  $ x_1 $ (i.e., the cost of making a type I error)  \n",
    "- $ c + A(p) $ is the expected cost associated with drawing one more $ z $  \n",
    "\n",
    "\n",
    "The optimal decision rule is characterized by two numbers $ \\alpha, \\beta \\in (0,1) \\times (0,1) $ that satisfy\n",
    "\n",
    "$$\n",
    "(1- p) L_0 < \\min \\{ p L_1, c + A(p) \\}  \\textrm { if } p \\geq \\alpha\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "p L_1 < \\min \\{ (1-p) L_0,  c + A(p) \\} \\textrm { if } p \\leq \\beta\n",
    "$$\n",
    "\n",
    "The optimal decision rule is then\n",
    "\n",
    "$$\n",
    "\\textrm { accept } x=x_0 \\textrm{ if } p \\geq \\alpha \\\\\n",
    "\\textrm { accept } x=x_1 \\textrm{ if } p \\leq \\beta \\\\\n",
    "\\textrm { draw another }  z \\textrm{ if }  \\beta \\leq p \\leq \\alpha\n",
    "$$\n",
    "\n",
    "Our aim is to compute the value function $ J $, and from it the associated cutoffs $ \\alpha $\n",
    "and $ \\beta $\n",
    "\n",
    "One sensible approach is to write the three components of $ J $\n",
    "that appear on the right side of the Bellman equation as separate functions\n",
    "\n",
    "Later, doing this will help us obey **the don’t repeat yourself (DRY)** golden rule of coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Let’s code this problem up and solve it\n",
    "\n",
    "To approximate the value function that solves Bellman equation [(1)](#equation-new1), we\n",
    "use value function iteration\n",
    "\n",
    "- For earlier examples of this technique see the [shortest path](short_path.ipynb#), [job search](mccall_model.ipynb#) or [optimal growth](optgrowth.ipynb#) lectures  \n",
    "\n",
    "\n",
    "As in the [optimal growth lecture](optgrowth.ipynb#), to approximate a continuous value function\n",
    "\n",
    "- We iterate at a finite grid of possible values of $ p $  \n",
    "- When we evaluate $ A(p) $ between grid points, we use linear interpolation  \n",
    "\n",
    "\n",
    "This means that to evaluate $ J(p) $ where $ p $ is not a grid point, we must use two points:\n",
    "\n",
    "- First, we use the largest of all the grid points smaller than $ p $, and call it $ p_i $  \n",
    "- Second, we use the grid point immediately after $ p $, named $ p_{i+1} $, to approximate the function value as  \n",
    "\n",
    "\n",
    "$$\n",
    "J(p) = J(p_i) + (p - p_i) \\frac{J(p_{i+1}) - J(p_i)}{p_{i+1} - p_{i}}\n",
    "$$\n",
    "\n",
    "In one dimension, you can think of this as simply drawing a line between each pair of points on the grid\n",
    "\n",
    "Here’s the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate as interp\n",
    "import quantecon as qe\n",
    "\n",
    "def expect_loss_choose_0(p, L0):\n",
    "    \"For a given probability return expected loss of choosing model 0\"\n",
    "    return (1 - p) * L0\n",
    "\n",
    "def expect_loss_choose_1(p, L1):\n",
    "    \"For a given probability return expected loss of choosing model 1\"\n",
    "    return p * L1\n",
    "\n",
    "def EJ(p, f0, f1, J):\n",
    "    \"\"\"\n",
    "    Evaluates the expectation of our value function J. To do this, we\n",
    "    need the current probability that model 0 is correct (p), the\n",
    "    distributions (f0, f1), and the function J.\n",
    "    \"\"\"\n",
    "    # Get the current distribution we believe (p*f0 + (1-p)*f1)\n",
    "    curr_dist = p * f0 + (1 - p) * f1\n",
    "    \n",
    "    # Get tomorrow's expected distribution through Bayes law\n",
    "    tp1_dist = np.clip((p * f0) / (p * f0 + (1 - p) * f1), 0, 1)\n",
    "    \n",
    "    # Evaluate the expectation\n",
    "    EJ = curr_dist @ J(tp1_dist)\n",
    "    \n",
    "    return EJ\n",
    "\n",
    "def expect_loss_cont(p, c, f0, f1, J):\n",
    "    return c + EJ(p, f0, f1, J)\n",
    "\n",
    "\n",
    "def bellman_operator(pgrid, c, f0, f1, L0, L1, J):\n",
    "    \"\"\"\n",
    "    Evaluates the value function for a given continuation value\n",
    "    function; that is, evaluates\n",
    "\n",
    "        J(p) = min((1 - p) L0, p L1, c + E J(p'))\n",
    "\n",
    "    Uses linear interpolation between points.\n",
    "    \"\"\"\n",
    "    m = np.size(pgrid)\n",
    "    assert m == np.size(J)\n",
    "    \n",
    "    J_out = np.zeros(m)\n",
    "    J_interp = interp.UnivariateSpline(pgrid, J, k=1, ext=0)\n",
    "\n",
    "    for (p_ind, p) in enumerate(pgrid):\n",
    "        # Payoff of choosing model 0\n",
    "        p_c_0 = expect_loss_choose_0(p, L0)\n",
    "        p_c_1 = expect_loss_choose_1(p, L1)\n",
    "        p_con = expect_loss_cont(p, c, f0, f1, J_interp)\n",
    "        \n",
    "        J_out[p_ind] = min(p_c_0, p_c_1, p_con)\n",
    "\n",
    "    return J_out\n",
    "\n",
    "\n",
    "#  == Now run at given parameters == #\n",
    "\n",
    "#  First set up distributions \n",
    "p_m1 = np.linspace(0, 1, 50)\n",
    "f0 = np.clip(st.beta.pdf(p_m1, a=1, b=1), 1e-8, np.inf)\n",
    "f0 = f0 / np.sum(f0)\n",
    "f1 = np.clip(st.beta.pdf(p_m1, a=9, b=9), 1e-8, np.inf)\n",
    "f1 = f1 / np.sum(f1)\n",
    "\n",
    "# Build a grid\n",
    "pg = np.linspace(0, 1, 251)\n",
    "# Turn the Bellman operator into a function with one argument\n",
    "bell_op = lambda vf: bellman_operator(pg, 0.5, f0, f1, 5.0, 5.0, vf)\n",
    "# Pass it to qe's built in iteration routine\n",
    "J = qe.compute_fixed_point(bell_op, \n",
    "                            np.zeros(pg.size),  # Initial guess\n",
    "                            error_tol=1e-6, \n",
    "                            verbose=True, \n",
    "                            print_skip=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running it produces the following output on our machine\n",
    "\n",
    "The distance column shows the maximal distance between successive iterates\n",
    "\n",
    "This converges to zero quickly, indicating a successful iterative procedure\n",
    "\n",
    "Iteration terminates when the distance falls below some threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more sophisticated implementation\n",
    "\n",
    "Now for some gentle criticisms of the preceding code\n",
    "\n",
    "By writing the code in terms of functions, we have to pass around\n",
    "some things that are constant throughout the problem\n",
    "\n",
    "- $ c $, $ f_0 $, $ f_1 $, $ L_0 $, and $ L_1 $  \n",
    "\n",
    "\n",
    "So now let’s turn our simple script into a class\n",
    "\n",
    "This will allow us to simplify the function calls and make the code more reusable\n",
    "\n",
    "We shall construct a class that\n",
    "\n",
    "- stores all of our parameters for us internally  \n",
    "- incorporates many of the same functions that we used above  \n",
    "- allows us, in addition, to simulate draws and the decision process under different prior beliefs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaldFriedman:\n",
    "    \"\"\"\n",
    "    Insert relevant docstrings here\n",
    "    \"\"\"\n",
    "    def __init__(self, c, L0, L1, f0, f1, m=25):\n",
    "        self.c = c\n",
    "        self.L0, self.L1 = L0, L1\n",
    "        self.m = m\n",
    "        self.pgrid = np.linspace(0.0, 1.0, m)\n",
    "\n",
    "        # Renormalize distributions so nothing is \"too\" small\n",
    "        f0 = np.clip(f0, 1e-8, 1-1e-8)\n",
    "        f1 = np.clip(f1, 1e-8, 1-1e-8)\n",
    "        self.f0 = f0 / np.sum(f0)\n",
    "        self.f1 = f1 / np.sum(f1)\n",
    "        self.J = np.zeros(m)\n",
    "\n",
    "    def current_distribution(self, p):\n",
    "        \"\"\"\n",
    "        This function takes a value for the probability with which\n",
    "        the correct model is model 0 and returns the mixed\n",
    "        distribution that corresponds with that belief.\n",
    "        \"\"\"\n",
    "        return p*self.f0 + (1-p)*self.f1\n",
    "\n",
    "    def bayes_update_k(self, p, k):\n",
    "        \"\"\"\n",
    "        This function takes a value for p, and a realization of the\n",
    "        random variable and calculates the value for p tomorrow.\n",
    "        \"\"\"\n",
    "        f0_k = self.f0[k]\n",
    "        f1_k = self.f1[k]\n",
    "\n",
    "        p_tp1 = p * f0_k / (p * f0_k + (1 - p) * f1_k)\n",
    "\n",
    "        return np.clip(p_tp1, 0, 1)\n",
    "\n",
    "    def bayes_update_all(self, p):\n",
    "        \"\"\"\n",
    "        This is similar to `bayes_update_k` except it returns a\n",
    "        new value for p for each realization of the random variable\n",
    "        \"\"\"\n",
    "        return np.clip(p * self.f0 / (p * self.f0 + (1 - p) * self.f1), 0, 1)\n",
    "\n",
    "    def payoff_choose_f0(self, p):\n",
    "        \"For a given probability specify the cost of accepting model 0\"\n",
    "        return (1 - p) * self.L0\n",
    "\n",
    "    def payoff_choose_f1(self, p):\n",
    "        \"For a given probability specify the cost of accepting model 1\"\n",
    "        return p * self.L1\n",
    "\n",
    "    def EJ(self, p, J):\n",
    "        \"\"\"\n",
    "        This function evaluates the expectation of the value function\n",
    "        at period t+1. It does so by taking the current probability\n",
    "        distribution over outcomes:\n",
    "\n",
    "            p(z_{k+1}) = p_k f_0(z_{k+1}) + (1-p_k) f_1(z_{k+1})\n",
    "\n",
    "        and evaluating the value function at the possible states\n",
    "        tomorrow J(p_{t+1}) where\n",
    "\n",
    "            p_{t+1} = p f0 / ( p f0 + (1-p) f1)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        p : Scalar(Float64)\n",
    "            The current believed probability that model 0 is the true\n",
    "            model.\n",
    "        J : Function\n",
    "            The current value function for a decision to continue\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        EJ : Scalar(Float64)\n",
    "            The expected value of the value function tomorrow\n",
    "        \"\"\"\n",
    "        # Pull out information\n",
    "        f0, f1 = self.f0, self.f1\n",
    "\n",
    "        # Get the current believed distribution and tomorrows possible dists\n",
    "        # Need to clip to make sure things don't blow up (go to infinity)\n",
    "        curr_dist = self.current_distribution(p)\n",
    "        tp1_dist = self.bayes_update_all(p)\n",
    "\n",
    "        # Evaluate the expectation\n",
    "        EJ = curr_dist @ J(tp1_dist)\n",
    "\n",
    "        return EJ\n",
    "\n",
    "    def payoff_continue(self, p, J):\n",
    "        \"\"\"\n",
    "        For a given probability distribution and value function give\n",
    "        cost of continuing the search for correct model\n",
    "        \"\"\"\n",
    "        return self.c + self.EJ(p, J)\n",
    "\n",
    "    def bellman_operator(self, J):\n",
    "        \"\"\"\n",
    "        Evaluates the value function for a given continuation value\n",
    "        function; that is, evaluates\n",
    "\n",
    "            J(p) = min(pL0, (1-p)L1, c + E[J(p')])\n",
    "\n",
    "        Uses linear interpolation between points\n",
    "        \"\"\"\n",
    "        payoff_choose_f0 = self.payoff_choose_f0\n",
    "        payoff_choose_f1 = self.payoff_choose_f1\n",
    "        payoff_continue = self.payoff_continue\n",
    "        c, L0, L1, f0, f1 = self.c, self.L0, self.L1, self.f0, self.f1\n",
    "        m, pgrid = self.m, self.pgrid\n",
    "\n",
    "        J_out = np.empty(m)\n",
    "        J_interp = interp.UnivariateSpline(pgrid, J, k=1, ext=0)\n",
    "\n",
    "        for (p_ind, p) in enumerate(pgrid):\n",
    "            # Payoff of choosing model 0\n",
    "            p_c_0 = payoff_choose_f0(p)\n",
    "            p_c_1 = payoff_choose_f1(p)\n",
    "            p_con = payoff_continue(p, J_interp)\n",
    "\n",
    "            J_out[p_ind] = min(p_c_0, p_c_1, p_con)\n",
    "\n",
    "        return J_out\n",
    "\n",
    "    def solve_model(self):\n",
    "        J = qe.compute_fixed_point(self.bellman_operator, np.zeros(self.m),\n",
    "                                   error_tol=1e-7, verbose=False)\n",
    "\n",
    "        self.J = J\n",
    "        return J\n",
    "\n",
    "    def find_cutoff_rule(self, J):\n",
    "        \"\"\"\n",
    "        This function takes a value function and returns the corresponding\n",
    "        cutoffs of where you transition between continue and choosing a\n",
    "        specific model\n",
    "        \"\"\"\n",
    "        payoff_choose_f0 = self.payoff_choose_f0\n",
    "        payoff_choose_f1 = self.payoff_choose_f1\n",
    "        m, pgrid = self.m, self.pgrid\n",
    "\n",
    "        # Evaluate cost at all points on grid for choosing a model\n",
    "        p_c_0 = payoff_choose_f0(pgrid)\n",
    "        p_c_1 = payoff_choose_f1(pgrid)\n",
    "\n",
    "        # The cutoff points can be found by differencing these costs with\n",
    "        # the Bellman equation (J is always less than or equal to p_c_i)\n",
    "        lb = pgrid[np.searchsorted(p_c_1 - J, 1e-10) - 1]\n",
    "        ub = pgrid[np.searchsorted(J - p_c_0, -1e-10)]\n",
    "\n",
    "        return (lb, ub)\n",
    "\n",
    "    def simulate(self, f, p0=0.5):\n",
    "        \"\"\"\n",
    "        This function takes an initial condition and simulates until it\n",
    "        stops (when a decision is made).\n",
    "        \"\"\"\n",
    "        # Check whether vf is computed\n",
    "        if np.sum(self.J) < 1e-8:\n",
    "            self.solve_model()\n",
    "\n",
    "        # Unpack useful info\n",
    "        lb, ub = self.find_cutoff_rule(self.J)\n",
    "        update_p = self.bayes_update_k\n",
    "        curr_dist = self.current_distribution\n",
    "\n",
    "        # Initialize a couple useful variables\n",
    "        decision_made = False\n",
    "        p = p0\n",
    "        t = 0\n",
    "\n",
    "        while decision_made is False:\n",
    "            # Maybe should specify which distribution is correct one so that\n",
    "            # the draws come from the \"right\" distribution\n",
    "            k = int(qe.random.draw(np.cumsum(f)))\n",
    "            t = t+1\n",
    "            p = update_p(p, k)\n",
    "            if p < lb:\n",
    "                decision_made = True\n",
    "                decision = 1\n",
    "            elif p > ub:\n",
    "                decision_made = True\n",
    "                decision = 0\n",
    "\n",
    "        return decision, p, t\n",
    "\n",
    "    def simulate_tdgp_f0(self, p0=0.5):\n",
    "        \"\"\"\n",
    "        Uses the distribution f0 as the true data generating\n",
    "        process\n",
    "        \"\"\"\n",
    "        decision, p, t = self.simulate(self.f0, p0)\n",
    "\n",
    "        if decision == 0:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "\n",
    "        return correct, p, t\n",
    "\n",
    "    def simulate_tdgp_f1(self, p0=0.5):\n",
    "        \"\"\"\n",
    "        Uses the distribution f1 as the true data generating\n",
    "        process\n",
    "        \"\"\"\n",
    "        decision, p, t = self.simulate(self.f1, p0)\n",
    "\n",
    "        if decision == 1:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "\n",
    "        return correct, p, t\n",
    "\n",
    "    def stopping_dist(self, ndraws=250, tdgp=\"f0\"):\n",
    "        \"\"\"\n",
    "        Simulates repeatedly to get distributions of time needed to make a\n",
    "        decision and how often they are correct.\n",
    "        \"\"\"\n",
    "        if tdgp == \"f0\":\n",
    "            simfunc = self.simulate_tdgp_f0\n",
    "        else:\n",
    "            simfunc = self.simulate_tdgp_f1\n",
    "\n",
    "        # Allocate space\n",
    "        tdist = np.empty(ndraws, int)\n",
    "        cdist = np.empty(ndraws, bool)\n",
    "\n",
    "        for i in range(ndraws):\n",
    "            correct, p, t = simfunc()\n",
    "            tdist[i] = t\n",
    "            cdist[i] = correct\n",
    "\n",
    "        return cdist, tdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s use our class to solve Bellman equation [(1)](#equation-new1) and verify that it gives similar output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up distributions\n",
    "p_m1 = np.linspace(0, 1, 50)\n",
    "f0 = np.clip(st.beta.pdf(p_m1, a=1, b=1), 1e-8, np.inf)\n",
    "f0 = f0 / np.sum(f0)\n",
    "f1 = np.clip(st.beta.pdf(p_m1, a=9, b=9), 1e-8, np.inf)\n",
    "f1 = f1 / np.sum(f1)\n",
    "\n",
    "# Create an instance\n",
    "wf = WaldFriedman(0.5, 5.0, 5.0, f0, f1, m=251)\n",
    "\n",
    "# Compute the value function\n",
    "wfJ = qe.compute_fixed_point(wf.bellman_operator, np.zeros(251),\n",
    "                             error_tol=1e-6, verbose=True, print_skip=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same output in terms of distance\n",
    "\n",
    "The approximate value functions produced are also the same\n",
    "\n",
    "Rather than discuss this further, let’s go ahead and use our code to generate some results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Now that our routines are working, let’s inspect the solutions\n",
    "\n",
    "We’ll start with the following parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_plot(c=1.25, L0=25, L1=25, a0=2.5, b0=2.0, a1=2.0, b1=2.5, m=25):\n",
    "\n",
    "    '''\n",
    "    c: Cost of another draw\n",
    "    L0: Cost of selecting x0 when x1 is true\n",
    "    L1: Cost of selecting x1 when x0 is true\n",
    "    a0, b0: Parameters for f0 (beta distribution)\n",
    "    a1, b1: Parameters for f1 (beta distribution)\n",
    "    m: Size of grid\n",
    "    '''\n",
    "\n",
    "    f0 = np.clip(st.beta.pdf(np.linspace(0, 1, m), a=a0, b=b0), 1e-6, np.inf)\n",
    "    f0 = f0 / np.sum(f0)\n",
    "    f1 = np.clip(st.beta.pdf(np.linspace(0, 1, m), a=a1, b=b1), 1e-6, np.inf)\n",
    "    f1 = f1 / np.sum(f1)  # Make sure sums to 1\n",
    "\n",
    "    # Create an instance of our WaldFriedman class\n",
    "    wf = WaldFriedman(c, L0, L1, f0, f1, m=m)\n",
    "    # Solve using qe's `compute_fixed_point` function\n",
    "    J = qe.compute_fixed_point(wf.bellman_operator, np.zeros(m),\n",
    "                               error_tol=1e-7, verbose=False,\n",
    "                               print_skip=10, max_iter=500)\n",
    "    lb, ub = wf.find_cutoff_rule(J)\n",
    "\n",
    "    # Get draws\n",
    "    ndraws = 500\n",
    "    cdist, tdist = wf.stopping_dist(ndraws=ndraws)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 9))\n",
    "\n",
    "    ax[0, 0].plot(f0, label=\"$f_0$\")\n",
    "    ax[0, 0].plot(f1, label=\"$f_1$\")\n",
    "    ax[0, 0].set(ylabel=\"probability of $z_k$\", xlabel=\"$k$\", title=\"Distributions\")\n",
    "    ax[0, 0].legend()\n",
    "\n",
    "    ax[0, 1].plot(wf.pgrid, J)\n",
    "    ax[0, 1].annotate(r\"$\\beta$\", xy=(lb + 0.025, 0.5), size=14)\n",
    "    ax[0, 1].annotate(r\"$\\alpha$\", xy=(ub + 0.025, 0.5), size=14)\n",
    "    ax[0, 1].vlines(lb, 0.0, wf.payoff_choose_f1(lb), linestyle=\"--\")\n",
    "    ax[0, 1].vlines(ub, 0.0, wf.payoff_choose_f0(ub), linestyle=\"--\")\n",
    "    ax[0, 1].set(ylim=(0, 0.5 * max(L0, L1)), ylabel=\"cost\",\n",
    "                       xlabel=\"$p_k$\", title=\"Value function $J$\")\n",
    "\n",
    "    # Histogram the stopping times\n",
    "    ax[1, 0].hist(tdist, bins=np.max(tdist))\n",
    "    ax[1, 0].set_title(f\"Stopping times over {ndraws} replications\")\n",
    "    ax[1, 0].set(xlabel=\"time\", ylabel=\"number of stops\")\n",
    "    ax[1, 0].annotate(f\"mean = {np.mean(tdist)}\", xy=(max(tdist) / 2,\n",
    "                      max(np.histogram(tdist, bins=max(tdist))[0]) / 2))\n",
    "\n",
    "    ax[1, 1].hist(cdist, bins=2)\n",
    "    ax[1, 1].set_title(f\"Correct decisions over {ndraws} replications\")\n",
    "    ax[1, 1].annotate(f\"% correct = {np.mean(cdist)}\",\n",
    "                      xy=(0.05, ndraws / 2))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analysis_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to generate this figure can be found in [wald_solution_plots.py](https://github.com/QuantEcon/QuantEcon.lectures.code/blob/master/wald_friedman/wald_solution_plots.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Function\n",
    "\n",
    "In the top left subfigure we have the two beta distributions, $ f_0 $ and $ f_1 $\n",
    "\n",
    "In the top right we have corresponding value function $ J $\n",
    "\n",
    "It equals $ p L_1 $ for $ p \\leq \\beta $, and $ (1-p )L_0 $ for $ p\n",
    "\\geq \\alpha $\n",
    "\n",
    "The slopes of the two linear pieces of the value function are determined by $ L_1 $\n",
    "and $ - L_0 $\n",
    "\n",
    "The value function is smooth in the interior region, where the posterior\n",
    "probability assigned to $ f_0 $ is in the indecisive region $ p \\in (\\beta, \\alpha) $\n",
    "\n",
    "The decision maker continues to sample until the probability that he attaches to model $ f_0 $ falls below $ \\beta $ or above $ \\alpha $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulations\n",
    "\n",
    "The bottom two subfigures show the outcomes of 500 simulations of the decision process\n",
    "\n",
    "On the left is a histogram of the stopping times, which equal the number of draws of $ z_k $ required to make a decision\n",
    "\n",
    "The average number of draws is around 6.6\n",
    "\n",
    "On the right is the fraction of correct decisions at the stopping time\n",
    "\n",
    "In this case the decision maker is correct 80% of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparative statics\n",
    "\n",
    "Now let’s consider the following exercise\n",
    "\n",
    "We double the cost of drawing an additional observation\n",
    "\n",
    "Before you look, think about what will happen:\n",
    "\n",
    "- Will the decision maker be correct more or less often?  \n",
    "- Will he make decisions sooner or later?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_plot(c=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what happens\n",
    "\n",
    "The stopping times dropped dramatically!\n",
    "\n",
    "Increased cost per draw has induced the decision maker usually to take only 1 or 2 draws before deciding\n",
    "\n",
    "Because he decides with less, the percentage of time he is correct drops\n",
    "\n",
    "This leads to him having a higher expected loss when he puts equal weight on both models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A notebook implementation\n",
    "\n",
    "To facilitate comparative statics, we provide a [Jupyter notebook](http://nbviewer.jupyter.org/github/QuantEcon/QuantEcon.notebooks/blob/master/Wald_Friedman.ipynb) that generates the same plots, but with sliders\n",
    "\n",
    "With these sliders you can adjust parameters and immediately observe\n",
    "\n",
    "- effects on the smoothness of the value function in the indecisive middle range as we increase the number of grid points in the piecewise linear  approximation.  \n",
    "- effects of different settings for the cost parameters $ L_0, L_1, c $, the parameters of two beta distributions $ f_0 $ and $ f_1 $, and the number of points and linear functions $ m $ to use in the piece-wise continuous approximation to the value function.  \n",
    "- various simulations from $ f_0 $ and associated distributions of waiting times to making a decision  \n",
    "- associated histograms of correct and incorrect decisions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Neyman-Pearson formulation\n",
    "\n",
    "For several reasons, it is useful to describe the theory underlying the test\n",
    "that Navy Captain G. S. Schuyler had been told to use and that led him\n",
    "to approach Milton Friedman and Allan Wallis to convey his conjecture\n",
    "that superior practical procedures existed\n",
    "\n",
    "Evidently, the Navy had told\n",
    "Captail Schuyler to use what it knew to be a state-of-the-art\n",
    "Neyman-Pearson test\n",
    "\n",
    "We’ll rely on Abraham Wald’s [[Wal47]](zreferences.ipynb#wald47) elegant summary of Neyman-Pearson theory\n",
    "\n",
    "For our purposes, watch for there features of the setup:\n",
    "\n",
    "- the assumption of a *fixed* sample size $ n $  \n",
    "- the application of laws of large numbers, conditioned on alternative\n",
    "  probability models, to interpret the probabilities $ \\alpha $ and\n",
    "  $ \\beta $ defined in the Neyman-Pearson theory  \n",
    "\n",
    "\n",
    "Recall that in the sequential analytic formulation above, that\n",
    "\n",
    "- The sample size $ n $ is not fixed but rather an object to be\n",
    "  chosen; technically $ n $ is a random variable  \n",
    "- The parameters $ \\beta $ and $ \\alpha $ characterize cut-off\n",
    "  rules used to determine $ n $ as a random variable  \n",
    "- Laws of large numbers make no appearances in the sequential\n",
    "  construction  \n",
    "\n",
    "\n",
    "In chapter 1 of **Sequential Analysis** [[Wal47]](zreferences.ipynb#wald47) Abraham Wald summarizes the\n",
    "Neyman-Pearson approach to hypothesis testing\n",
    "\n",
    "Wald frames the problem as making a decision about a probability\n",
    "distribution that is partially known\n",
    "\n",
    "(You have to assume that *something* is already known in order to state a well posed problem.\n",
    "Usually, *something* means *a lot*.)\n",
    "\n",
    "By limiting  what is unknown, Wald uses the following simple structure\n",
    "to illustrate the main ideas.\n",
    "\n",
    "- a decision maker wants to decide which of two distributions\n",
    "  $ f_0 $, $ f_1 $ govern an i.i.d. random variable $ z $  \n",
    "- The null hypothesis $ H_0 $ is the statement that $ f_0 $\n",
    "  governs the data.  \n",
    "- The alternative hypothesis $ H_1 $ is the statement that\n",
    "  $ f_1 $ governs the data.  \n",
    "- The problem is to devise and analyze a test of hypothesis\n",
    "  $ H_0 $ against the alternative hypothesis $ H_1 $ on the\n",
    "  basis of a sample of a fixed number $ n $ independent\n",
    "  observations $ z_1, z_2, \\ldots, z_n $ of the random variable\n",
    "  $ z $.  \n",
    "\n",
    "\n",
    "To quote Abraham Wald,\n",
    "\n",
    "- A test procedure leading to the acceptance or rejection of the\n",
    "  hypothesis in question is simply a rule specifying, for each possible\n",
    "  sample of size $ n $, whether the hypothesis should be accepted\n",
    "  or rejected on the basis of the sample. This may also be expressed as\n",
    "  follows: A test procedure is simply a subdivision of the totality of\n",
    "  all possible samples of size $ n $ into two mutually exclusive\n",
    "  parts, say part 1 and part 2, together with the application of the\n",
    "  rule that the hypothesis be accepted if the observed sample is\n",
    "  contained in part 2. Part 1 is also called the critical region. Since\n",
    "  part 2 is the totality of all samples of size 2 which are not\n",
    "  included in part 1, part 2 is uniquely determined by part 1. Thus,\n",
    "  choosing a test procedure is equivalent to determining a critical\n",
    "  region.  \n",
    "\n",
    "\n",
    "Let’s listen to Wald longer:\n",
    "\n",
    "- As a basis for choosing among critical regions the following\n",
    "  considerations have been advanced by Neyman and Pearson: In accepting\n",
    "  or rejecting $ H_0 $ we may commit errors of two kinds. We commit\n",
    "  an error of the first kind if we reject $ H_0 $ when it is true;\n",
    "  we commit an error of the second kind if we accept $ H_0 $ when\n",
    "  $ H_1 $ is true. After a particular critical region $ W $ has\n",
    "  been chosen, the probability of committing an error of the first\n",
    "  kind, as well as the probability of committing an error of the second\n",
    "  kind is uniquely determined. The probability of committing an error\n",
    "  of the first kind is equal to the probability, determined by the\n",
    "  assumption that $ H_0 $ is true, that the observed sample will be\n",
    "  included in the critical region $ W $. The probability of\n",
    "  committing an error of the second kind is equal to the probability,\n",
    "  determined on the assumption that $ H_1 $ is true, that the\n",
    "  probability will fall outside the critical region $ W $. For any\n",
    "  given critical region $ W $ we shall denote the probability of an\n",
    "  error of the first kind by $ \\alpha $ and the probability of an\n",
    "  error of the second kind by $ \\beta $.  \n",
    "\n",
    "\n",
    "Let’s listen carefully to how Wald applies a law of large numbers to\n",
    "interpret $ \\alpha $ and $ \\beta $:\n",
    "\n",
    "- The probabilities $ \\alpha $ and $ \\beta $ have the\n",
    "  following important practical interpretation: Suppose that we draw a\n",
    "  large number of samples of size $ n $. Let $ M $ be the\n",
    "  number of such samples drawn. Suppose that for each of these\n",
    "  $ M $ samples we reject $ H_0 $ if the sample is included in\n",
    "  $ W $ and accept $ H_0 $ if the sample lies outside\n",
    "  $ W $. In this way we make $ M $ statements of rejection or\n",
    "  acceptance. Some of these statements will in general be wrong. If\n",
    "  $ H_0 $ is true and if $ M $ is large, the probability is\n",
    "  nearly $ 1 $ (i.e., it is practically certain) that the\n",
    "  proportion of wrong statements (i.e., the number of wrong statements\n",
    "  divided by $ M $) will be approximately $ \\alpha $. If\n",
    "  $ H_1 $ is true, the probability is nearly $ 1 $ that the\n",
    "  proportion of wrong statements will be approximately $ \\beta $.\n",
    "  Thus, we can say that in the long run [ here Wald applies a law of\n",
    "  large numbers by driving $ M \\rightarrow \\infty $ (our comment,\n",
    "  not Wald’s) ] the proportion of wrong statements will be\n",
    "  $ \\alpha $ if $ H_0 $is true and $ \\beta $ if\n",
    "  $ H_1 $ is true.  \n",
    "\n",
    "\n",
    "The quantity $ \\alpha $ is called the *size* of the critical region,\n",
    "and the quantity $ 1-\\beta $ is called the *power* of the critical\n",
    "region.\n",
    "\n",
    "Wald notes that\n",
    "\n",
    "- one critical region $ W $ is more desirable than another if it\n",
    "  has smaller values of $ \\alpha $ and $ \\beta $. Although\n",
    "  either $ \\alpha $ or $ \\beta $ can be made arbitrarily small\n",
    "  by a proper choice of the critical region $ W $, it is possible\n",
    "  to make both $ \\alpha $ and $ \\beta $ arbitrarily small for a\n",
    "  fixed value of $ n $, i.e., a fixed sample size.  \n",
    "\n",
    "\n",
    "Wald summarizes Neyman and Pearson’s setup as follows:\n",
    "\n",
    "- Neyman and Pearson show that a region consisting of all samples\n",
    "  $ (z_1, z_2, \\ldots, z_n) $ which satisfy the inequality  \n",
    "  \n",
    "      $$\n",
    "  \\frac{ f_1(z_1) \\cdots f_1(z_n)}{f_0(z_1) \\cdots f_1(z_n)} \\geq k\n",
    "  $$\n",
    "  \n",
    "  is a most powerful critical region for testing the hypothesis\n",
    "  $ H_0 $ against the alternative hypothesis $ H_1 $. The term\n",
    "  $ k $ on the right side is a constant chosen so that the region\n",
    "  will have the required size $ \\alpha $.  \n",
    "\n",
    "\n",
    "Wald goes on to discuss Neyman and Pearson’s concept of *uniformly most\n",
    "powerful* test.\n",
    "\n",
    "Here is how Wald introduces the notion of a sequential test\n",
    "\n",
    "- A rule is given for making one of the following three decisions at any stage of\n",
    "  the experiment (at the m th trial for each integral value of m ): (1) to\n",
    "  accept the hypothesis H , (2) to reject the hypothesis H , (3) to\n",
    "  continue the experiment by making an additional observation. Thus, such\n",
    "  a test procedure is carried out sequentially. On the basis of the first\n",
    "  observation one of the aforementioned decisions is made. If the first or\n",
    "  second decision is made, the process is terminated. If the third\n",
    "  decision is made, a second trial is performed. Again, on the basis of\n",
    "  the first two observations one of the three decisions is made. If the\n",
    "  third decision is made, a third trial is performed, and so on. The\n",
    "  process is continued until either the first or the second decisions is\n",
    "  made. The number n of observations required by such a test procedure is\n",
    "  a random variable, since the value of n depends on the outcome of the\n",
    "  observations.  \n",
    "\n",
    "\n",
    "Footnotes1Because the decision maker believes that $ z_{k+1} $ is\n",
    "drawn from a mixture of two i.i.d. distributions, he does *not*\n",
    "believe that the sequence $ [z_{k+1}, z_{k+2}, \\ldots] $ is i.i.d.\n",
    "Instead, he believes that it is *exchangeable*. See [[Kre88]](zreferences.ipynb#kreps88)\n",
    "chapter 11, for a discussion of exchangeability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}